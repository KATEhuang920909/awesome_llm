### 存储&初始化内存空间

* 需占用内存/显存空间：
  $$
  S=\frac {参数量*10^9*字符占用大小}{1024^3}
    
  $$
  对于参数量为6b的chatglm，若采用半精度fp16，每个字符占用大小为2bit，则需占用内存/显存空间约为11.2G

### 混合精度训练

![img](https://pic4.zhimg.com/80/v2-5e80264a8fe8ffaf312d08a50ce103eb_1440w.webp)

	* fp16 最大限度提高表示范围和精度：

​		取值范围计算公式：
$$
S=(-1)^{sign} *(1.0+fraction)*2^{(exponent-15)}
$$
exponent取值范围[0,30]、fraction取值范围（0，1）
$$
S_{max}= 2^{16}  ;S_{min} =-2^{16}
$$
​			通过fp16的表达公式可知，增加fraction可以提高表示的精度，增加exponent可以提高表示的范围。计算机中存储位数是有限的，所以需要在表示范围和精度之间权衡，如果fraction过大，此时获得了较高的精度，但是可以表示的数值范围就有限。

​	精度：
$$
2^{-10} = 10^{-x} => x=10lg2  ==>x==3.01
$$
​	可以精确到小数点第三位

 * bf16:最大限度提高表示范围和精度：

   * $$
     S_{max} =(-1)^{sign} *(1.0+fraction)*2^{(2^{8}-15)}=2^{242};
     S_{min} =-2^{242}
     $$

     $$
     2^{-7} = 10^{-x} => x=7lg2  ==>x==2.11
     $$

​		可以精确到小数点后两位。



### deepspeed

1.数据并行

baseline:传统的数据并行策略，每张GPU上存储全部模型的权重、梯度和优化器等参数，每张卡上秉性训练不同数据，实现参数聚合，并分别更新权重。

stage1：优化器并行；将优化器的状态参数分发到不同gpu上；

stage2：梯度+优化器并行：基于stage1上再对梯度进行分布式存储。

stage3：梯度+优化器+权重并行：模型所有参数进行分布式存储



图解stage3的训练过程：（to be continued）

初始阶段：假设两张卡只存一层transformer，

![image-20231101153918048](C:\Users\huangkai\AppData\Roaming\Typora\typora-user-images\image-20231101153918048.png)

![image-20231101154301173](C:\Users\huangkai\AppData\Roaming\Typora\typora-user-images\image-20231101154301173.png)

![image-20231101154312996](C:\Users\huangkai\AppData\Roaming\Typora\typora-user-images\image-20231101154312996.png)



### cpu offload

​		cpu offload 允许一个back propagation 中，将参数动态的在cpu和gpu之间相互转移，从而节省gpu显存。举个栗子：

```python
import torch 
from torch import nn
class TorchCPUOffload(nn.Module):
    def __init__(self, module):
        super().__init__()
        self.module = module

    def forward(self, *args, **kwargs):
        with torch.autograd.graph.save_on_cpu(pin_memory=True):
            return self.module(*args, **kwargs)

model = nn.Sequential(
    nn.Linear(10, 100),
    TorchCPUOffload(nn.Linear(100, 100)),
    nn.Linear(100, 10),
)

x = torch.randn(10)
loss = model(x).sum()
loss.backward()
```

​		class TorchCPUOffload(nn.Module):上面的代码定义了一个包括三层全连接层的网络，通过 torch.autograd.graph.save_on_cpu 的方法，第二层全连接层所产生的中间变量，会在不用时移动到 CPU 中，以减少显存占用。

### int8 量化

目的：减少内存消耗

方法：将浮点数x，通过缩放因子scale映射到范围[-128,127]内的8bit表示，即：
$$
x_q = Clip(round(\frac{x_f}{scale}))
$$
缩放因子scale按如下公式得到：
$$
amax  = max(abs(x_f))
$$

$$
scale = \frac{(2*amax)}{254}
$$

实例：

![img](https://pic4.zhimg.com/v2-af2eaf59e0e9409d1587fe9ba82dadcb_r.jpg)

### 梯度累积

​		显存的占用直接受到输入数据的影响，包括Batch size、Sequence length等，如果显存溢出，我们最直接的做法就是将Batch size调低。但是降低Batch size可能会降低模型的效果。

​		为了不降低Batch size，可以采用梯度累积的方法。梯度累积是指在前向传播之后所计算梯度并不立刻用于参数更新，而是接着继续下一轮的前向传播，每次计算的梯度会暂时存储下来，待在若干次前向传播之后，一并对所有梯度进行参数更新。因此梯度累积相当于是拿时间换空间。

​	hugging face 中Transformers 库对应的参数为：

```python
--gradient_accumulation_steps=2
```

2代表累积两轮向后传播，相当于batch扩大一倍，训练总耗时也扩大一倍。

### 梯度检查点



###  Flash Attention