

### **一、压测核心目标**

1. **吞吐量**：单位时间处理的请求数（如：QPS - Queries Per Second）。
2. **延迟**：单个请求从发送到接收响应的耗时（P50/P95/P99）。
3. **资源消耗**：CPU/GPU利用率、内存占用、显存占用、网络IO。
4. **容错能力**：高并发下是否崩溃、错误率是否飙升。
5. **扩展性**：水平/垂直扩展能否线性提升性能。

### **二、压测工具选择**

| 工具名称               | 适用场景               | 特点                          |
| ---------------------- | ---------------------- | ----------------------------- |
| **Locust**             | HTTP/HTTPS协议（推荐） | 分布式、Python脚本、Web可视化 |
| **TensorRT LLM Bench** | 大模型专用（如LLM）    | 支持动态批处理、KV缓存分析    |

### **三、压测关键步骤**

#### 1. **构建真实测试数据**

- 避免重复数据：使用多样化的输入（如不同长度的文本、各类图片）。
- 数据预热：如模型首次加载需初始化（预热），避免计入延迟统计。
- 示例：文本生成模型需构造不同主题/长度的prompt。

#### 2. **模拟合理请求模式**

- **并发用户数**：逐步增加并发（如从10→1000），观察性能拐点。
- **请求分布**：使用泊松分布（Poisson Distribution）模拟真实用户间隔。
- **动态批处理**（关键）：若服务端支持批处理，需测试不同批量大小（batch size）下的吞吐量。

#### 3. **配置压测环境**

- **隔离环境**：压测环境需独立于生产环境（避免干扰）。
- **资源监控**：使用`nvidia-smi`（GPU）、`prometheus+grafana`（全栈监控）。
- **网络优化**：确保压测机与服务端网络低延迟（同机房最佳）。

#### 4. **设计压测场景**

| 场景类型     | 目的                          | 示例参数                 |
| :----------- | :---------------------------- | :----------------------- |
| **基准测试** | 单请求性能                    | 并发=1，持续1分钟        |
| **负载测试** | 模拟预期峰值                  | 并发=100（业务预估峰值） |
| **压力测试** | 突破极限，找崩溃点            | 并发从100→2000阶梯递增   |
| **耐力测试** | 长时间运行（如24h）查内存泄漏 | 并发=50，持续24小时      |

#### 5. **执行压测**

bash

```
# Locust 示例命令（启动100用户，每秒增加5个）
locust -f stress_test.py --headless -u 100 -r 5 -t 1h
```

#### 6. **监控指标**

- **服务端**：GPU利用率（目标70%~90%）、显存占用、推理延迟、错误日志。
- **客户端**：请求成功率、延迟分布（P99是关键！）。
- **特殊指标**：
  - Token生成速度（LLM）：Tokens/sec
  - 批处理效率：动态批处理命中率

#### 7. **分析瓶颈**

- **GPU未跑满** → 可能受限于CPU预处理/后处理或网络IO。
- **延迟陡增** → 检查队列堆积、内存交换（OOM风险）。
- **错误率上升** → 查看服务日志（常见：超时、显存不足）。

### **四、AI模型压测特有挑战**

1. **动态批处理（Dynamic Batching）**
   - 框架支持（TensorRT-LLM、vLLM、Triton Inference Server）。
   - 测试不同批处理策略对吞吐量的影响。
2. **长文本/大输入处理**
   - 构造极端输入（如10k tokens的文本），测试显存溢出风险。
3. **流式响应（Streaming）**
   - 模拟分段返回数据（如LLM逐token生成），测试并发流能力。
4. **模型热加载**
   - 测试切换模型版本时的性能波动。

------

### **五、优化建议**

- **GPU层面**：开启FP16/INT8量化、使用TensorRT优化。
- **服务层面**：
  - 异步处理（Python `async`/`await`）。
  - 自适应批处理（根据输入长度动态调整batch size）。
- **架构层面**：
  - 水平扩展：通过负载均衡部署多个模型实例。
  - 缓存结果：对重复请求缓存输出（如Redis）。

------

### **六、压测报告模板**



```markdown
## 压力测试报告
### 目标模型
- 模型ID：bert-base-uncased  
- 部署方式：Triton+TensorRT（GPU T4）

### 压测参数
- 并发用户：10 → 500（阶梯上升）
- 测试时长：30分钟
- 请求数据：随机文本（长度50~200 tokens）

### 关键指标
| 并发数 | QPS  | P99延迟(ms) | GPU利用率 | 错误率 |
|--------|------|-------------|-----------|--------|
| 50     | 120  | 210         | 65%       | 0%     |
| 200    | 380  | 450         | 92%       | 0%     |
| 500    | 420  | 1200        | 95%       | 15%    |

### 结论
- 瓶颈点：并发>200时，显存不足导致OOM错误。
- 建议：优化批处理策略或升级GPU显存。
```

------

通过系统化的压测，不仅能发现性能瓶颈，还能为资源扩容、模型优化提供数据支撑。**切记：压测不是一次性任务，而应伴随模型迭代持续进行。** 尤其是在流量增长或模型升级后，重新压测是保障稳定性的必要手段。

